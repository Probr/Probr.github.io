<navbar></navbar>

<div class="row">

    <div class="container content">
        <div class="row">

            <div class="col-lg-3 side-nav-col">
                <section sticky-nav>
                    <h1>Contents</h1>

                    <ul class="nav nav-pills nav-stacked">

                        <li><a href="/#/docs/analysis#architecture">Architecture</a></li>
                        <li><a href="/#/docs/analysis#data-model">Data Model</a></li>
                        <li><a href="/#/docs/analysis#frontend">Front-End</a></li>
                        <li><a href="/#/docs/analysis#rest">REST API</a></li>

                        <h3>Async Workers</h3>
                        <li><a href="/#/docs/analysis#sessions-worker">Sessions</a></li>
                        <li><a href="/#/docs/analysis#locations-worker">Locations</a></li>
                        <li><a href="/#/docs/analysis#devices-worker">Devices</a></li>


                    </ul>
                </section>
            </div>

            <div class="col-lg-9">

                <h1>probr-analysis</h1>

                <h2><a name="architecture">Architecture</a></h2>

                <p>
                    The diagram below shows the architecture of the probr-analysis application.
                    Note that the database that serves as a storage and source for the packets is the same database that is
                    fed by the <a href="/#/docs/core">probr-core system</a> .
                </p>

                <img class="doc-img img-responsive" src="assets/images/architecture_analysis.png"/>

                <p>
                    probr-analysis is a multi-tiered web application. The frontend is a standard HTML5 and JavaScript web
                    frontend. It provides the
                    graphical user interface that allows to explore the data collected in the first step by probr-core. The
                    backend is written in NodeJS and provides
                    the REST API endpoints for the frontend. A very important part of probr-analysis are the workers.
                    They asynchronously aggregate the raw packet data into more sophisticated data models such as sessions, locations, or devices.
                </p>


                <h2><a name="data-model">Data Model</a></h2>
                The domain of probr-analysis deals with four types of entities: packets, devices, locations, and sessions.
                The packets are the main source of information in the system. They come from the probr-core sniffing component. The other
                three entity types are aggregated and calculated by our <a href="/#/docs/analysis#sessions-worker">workers</a>. The diagram
                below shows the main entities in probr-analysis:
                <p>
                    <img class="doc-img img-responsive" src="assets/images/data_model.png"/>
                </p>

                <h2><a name="frontend">Front-End</a></h2>

                <p>
                    Optional URL Parameters (all apart from the Live View):
                </p>
                <pre><code>startTimestamp: Start of the selected time range, UNIX timestamp<br>endTimestamp: End of the selected time range, UNIX timestamp<br>tags: the selected tag as a single string</code></pre>

                <h3>Live View</h3>
                <pre><code>/live</code></pre>
                <ul>
                    <li>Displays incoming packets from the probr-core sniffers in real time.</li>
                    <li>Displays identified devices in the intervals: last five minutes, last hour, and last day.</li>
                </ul>

                <h3>Log View</h3>
                <pre><code>/packets</code></pre>
                <ul>
                    <li>Displays a log of all sniffed packets.</li>
                    <li>The user can restrict or filter the data by setting a tag and a date/time range in the navigation bar.
                    </li>
                </ul>

                <h3>Utilization View</h3>
                <pre><code>/utilization</code></pre>
                <ul>
                    <li>Displays the utilization graph for the chosen tag and date/time range.</li>
                    <li>Displays the loyalty graph for the chosen tag and date/time range.</li>
                    <li>Displays the swimlane graph for the current data of the utilization graph.</li>
                    <li>The user can zoom within the swimlane graph and move around in the date/time range.</li>
                </ul>

                <h3>Location View</h3>
                <pre><code>/heatmap</code></pre>
                <ul>
                    <li>Displays an interactive map containing the locations as a heatmap.</li>
                    <li>The user can restrict or filter the data by setting a tag and a date/time range in the navigation bar.
                    </li>
                </ul>

                <h3>Stats View</h3>
                <pre><code>/devices</code></pre>
                <ul>
                    <li>Displays a chart of the vendor statistics for the selected tag and time range.</li>
                    <li>Displays a ranking of vendors based on identified device count and percentage.</li>
                    <li>Displays statistics about MAC randomization in the identified device data.</li>
                    <li>The user can restrict or filter the data by setting a tag and a date/time range in the navigation bar.
                    </li>
                </ul>

                <h3>Tracking View</h3>
                <pre><code>/mac</code></pre>
                <ul>
                    <li>The user can add named aliases for MAC addresses to be tracked.</li>
                    <li>The presence patterns of tracked aliases are displayed in a swimlane graph</li>
                    <li>The user can zoom within the swimlane graph and move around in the date/time range</li>
                    <li>The user can restrict or filter the data by setting a tag and a date/time range in the navigation bar.
                    </li>
                </ul>

                <h2><a name="rest">REST API</a></h2>

                <h3>Devices</h3>
                <p>
                    <rest-api methods="['GET/LIST']" , payload="deviceObj" path="'/api/device/query?starTimestamp={timestamp}&endTimestamp={timestamp}&tags={tag}'"
                              description="'Get devices identified in a certain time range and with a certain tag.'"></rest-api>
                    <!-- not used anymore in analysis
                        <rest-api methods="['GET/LIST']" , payload="deviceObj" path="'/api/device/lastFive'"
                                  description="'Get devices seen in the last 5 minutes.'"></rest-api>
                        <hr />
                        <rest-api methods="['GET/LIST']" , payload="deviceObj" path="'/api/device/lastHour'"
                                  description="'Get devices seen in the last hour.'"></rest-api>
                        <hr />
                        <rest-api methods="['GET/LIST']" , payload="deviceObj" path="'/api/device/lastDay'"
                                  description="'Get devices seen in the last hour.'"></rest-api>
                    -->
                </p>

                <h3>Locations</h3>
                <p>
                    <rest-api methods="['GET/LIST']" , payload="locationObj" path="'/api/locations?query={URL-encoded MongoDB query object}'"
                              description="'You can use arbitrary MongoDB query objects.'"></rest-api>
                </p>


                <h3>Sessions</h3>
                <p>
                    <rest-api methods="['GET/LIST']" , payload="sessionObj" path="'/api/session?query={URL-encoded MongoDB query object}'"
                              description="'You can use arbitrary MongoDB query objects.'"></rest-api>
                <hr/>
                <rest-api methods="['GET/LIST']" , payload="sessionReduceObj" path="'/api/session/reduce?startTimestamp={timestamp}&endTimestamp={timestamp}&tags={tag}'"
                          description="'Gets the aggregated session data for the utilization view, according to the passed timestamps and tag.'"></rest-api>
                </p>

                <h3>Packets</h3>
                <p>
                    <rest-api methods="['GET/LIST']" , payload="packetObj" path="'/api/packets/count?query={URL-encoded MongoDB query object}'"
                              description="'On this endpoint, you can choose what parameters you use. You can use arbitrary MongoDB query objects and can filter packets arbitrarily and also use MongoDB features like sorting.'"></rest-api>
                </p>

                <h2><a name="workers">Async workers</a></h2>

                <p>
                    In order to answer more sophisticated questions (see <a href="/#/usecase#questions">here</a>) in a timely manner,
                    incremental preprocessing and aggregation of the raw packet data is required.
                    The amount of raw packet data is too large to perform aggregation queries on demand (i.e., when the user requests some data).
                    Therefore, probr-analysis employs a worker system that periodically runs asynchronous tasks in order
                    to aggregate the information of interest in advance.
                </p>

                <p>
                    There are three worker tasks in probr-analysis:
                <ul>
                    <li>Session-Worker</li>
                    <li>Location-Worker</li>
                    <li>Device-Worker</li>
                </ul>
                </p>
                <p>
                    The worker tasks are encapsulated in a separate node app, which can be started independently from the rest of
                    probr-analysis.
                    You can find the code for the worker tasks <a
                        href="https://github.com/probr/probr-analysis/tree/master/worker">here</a>. In the following, the computations
                    that are conducted by the
                    workers are explained.
                </p>

                <h3><a name="sessions-worker">Sessions</a></h3>

                <p>
                    A session is defined as the time interval that a certain MAC address was present at a location monitored by
                    our
                    sniffing devices. Our definition of a MAC address being 'present' is: The device with said MAC address is
                    present if
                    we have collected probes for it with less than 5 minutes in between. Let's look at an example:
                </p>
                <img class="doc-img img-responsive" src="assets/images/sessions.png"/>

                <p>
                    Here, the packets #1 and #2 belong to the same session, because they are less than 5 minutes apart. The next
                    packet, although
                    from the same MAC address, does not belong to the same session because the inter-packet time is too large. Hence, packet #3
                    starts a new session
                    on its own. A session that consists only of one packet (thus having a duration of 0) is not considered in
                    our system. Depending
                    on the use case, you might want to tweak the 5 minute session threshold and also decide to ignore sessions
                    below a certain length.
                </p>

                <p>
                    In the actual implementation, the session aggregation task is implemented as a MapReduce algorithm. You can
                    check out the
                    corresponding code <a
                        href="https://github.com/probr/probr-analysis/blob/master/worker/components/session/session.mapreduce.js">here</a>.
                </p>


                <h3><a name="locations-worker">Locations</a></h3>

                <p>
                    How is it possible to compute geographical locations out of the sniffed probe requests/packets ? The fact that
                    the probe
                    requests contain the measured signal strength makes it possible to compute locations by <a
                        href="https://en.wikipedia.org/wiki/Trilateration">trilateration</a>.
                </p>
                <p>
                    To employ trilateration, the user has to set a correct latitude and longitude for the sniffing devices when
                    initially setting up the probr-core sniffing system. These will in turn assign their lat/lng location data to each
                    of the packets they sniff. Now each packet contains a lat/lng location and a measured signal strength in dbM.
                </p>
                <p>
                    The first step the location task performs is to extract raw locations from the sniffed packets. This is accomplished
                    through a MapReduce algorithm that runs directly on the MongoDB. The MapReduce algorithm first maps together all packets
                    that were sniffed within the same minute and have the same source MAC address. Then it extracts location and
                    signal strength for all packets in that minute/MAC address mapping. The raw loaction now links this array of
                    lat/lng locations and signal strength values to a time and MAC address key. These objects are then stored in a raw locations
                    collection.
                </p>
                <p>
                    Then the algorithm incrementally iterates over the raw locations and performs the actual trilateration.
                    The following listing outlines the algorithm:
                </p>
                <img class="doc-img img-responsive" src="assets/images/location_algorithm.png"/>


                <p>
                    This process is visualized in the following animation:
                </p>
                <img class="doc-img img-responsive" src="assets/images/gifs/location.gif"/>

                <h3><a name="devices-worker">Devices</a></h3>

                <p>
                    The device task runs on a regular interval and takes all packets into consideration that have been added to the system since
                    the previous pass. On every pass, the device task goes through all packets and extracts unique MAC addresses.
                    If the MAC address is already identified as a device by a previous pass of the task, only its last_seen property is updated to the
                    timestamp of the packet. Otherwise, if the MAC address is not yet identified, the device task consults the
                    <a href="http://standards-oui.ieee.org/oui.txt"> IEEE IOU</a> database for MAC address vendor prefixes. By querying the database
                    with the first three octets of the corresponding MAC address, we can gather information about the vendor of that device.
                </p>
            </div>

        </div>

    </div>
</div>

</div>
<footer></footer>
