<navbar></navbar>

<div class="row">

  <div class="container content">
    <div class="row">

      <div class="col-lg-3 side-nav-col">
        <section sticky-nav>
          <h1>Contents</h1>

          <ul class="nav nav-pills nav-stacked">

            <li><a href="/#/docs/analysis#architecture">Architecture</a></li>
            <li><a href="/#/docs/analysis#frontend">Front-End</a></li>
            <li><a href="/#/docs/analysis#rest">REST API</a></li>

            <h3>Async Workers</h3>
            <li><a href="/#/docs/analysis#sessions-worker">Sessions</a></li>
            <li><a href="/#/docs/analysis#locations-worker">Locations</a></li>
            <li><a href="/#/docs/analysis#devices-worker">Devices</a></li>

            <h3>Usage</h3>
            <li><a href="/#/docs/analysis#usage">Samples</a></li>

          </ul>
        </section>
      </div>

      <div class="col-lg-9">

        <h1>probr-analysis</h1>

        <h2><a name="architecture">Architecture</a></h2>

        <p>
          The diagram below shows the architecture of the probr-analysis application.
          Note that the database that serves as a storage and source for the packets is the same database that is
          fed by the <a href="/#/docs/core">probr-core system</a> .
        </p>

        <img class="doc-img img-responsive" src="assets/images/architecture_analysis.png"/>

        <p>
          probr-analysis is a multi-tiered web application. The frontend is a standard HTML5 and JavaScript web
          frontend. It provides the
          graphical user interface that allows to explore the data collected in the first step by probr-core. The
          backend is written in NodeJS and provides
          the REST API endpoints for the frontend. A very important part of probr-analysis are the workers. The workers
          are somewhat independent jobs that run asynchronously and
          aggregate the raw packet data into more sophisticated data models such as sessions, locations or devices.

        </p>

        <h2><a name="frontend">Front-End</a></h2>

        <h3>Live View</h3>
        <small>
          <pre><code>/live</code></pre>
        </small>
        <ul>
          <li>Displays live incoming packets from the probr-core sniffers.</li>
          <li>Displays identified devices in last five minutes, last hour and last day.</li>
        </ul>

        <h3>Log View</h3>
        <small>
          <pre><code>/packets</code></pre>
        </small>
        <ul>
          <li>Displays a log of all sniffed packets.</li>
          <li>The user can restrict or filter the data by setting a tag and a date/time range in the navigation bar.
          </li>
        </ul>
        <small>
          Optional URL Parameters:
          <pre><code>startTimestamp: Start of the selected timerange, UNIX timestamp</code></pre>
          <pre><code>endTimestamp: End of the selected timerange, UNIX timestamp</code></pre>
          <pre><code>tags: the selected tag as a single string</code></pre>
        </small>

        <h3>Utilization View</h3>
        <small>
          <pre><code>/utilization</code></pre>
        </small>
        <ul>
          <li>Displays the utilization graph for the chosen tag and date/time range.</li>
          <li>Displays the loyalty graph for the chosen tag and date/time range.</li>
          <li>Displays the swimlane graph for the current data of the utilization graph.</li>
          <li>The user can zoom in the swimlane graph and move around in the date/time range.</li>
          </li>
        </ul>
        <small>
          Optional URL Parameters:
          <pre><code>startTimestamp: Start of the selected timerange, UNIX timestamp</code></pre>
          <pre><code>endTimestamp: End of the selected timerange, UNIX timestamp</code></pre>
          <pre><code>tags: the selected tag as a single string</code></pre>
        </small>

        <h3>Location View</h3>
        <small>
          <pre><code>/heatmap</code></pre>
        </small>
        <ul>
          <li>Displays an interactive map containing the locations as a heatmap.</li>
          <li>The user can restrict or filter the data by setting a tag and a date/time range in the navigation bar.
          </li>
        </ul>
        <small>
          Optional URL Parameters:
          <pre><code>startTimestamp: Start of the selected timerange, UNIX timestamp</code></pre>
          <pre><code>endTimestamp: End of the selected timerange, UNIX timestamp</code></pre>
          <pre><code>tags: the selected tag as a single string</code></pre>
        </small>

        <h3>Stats View</h3>
        <small>
          <pre><code>/devices</code></pre>
        </small>
        <ul>
          <li>Displays a chart of the vendor statistics for the selected tag and time range.</li>
          <li>Displays a ranking of vendors based on identified device count and percentage.</li>
          <li>Displays statistics about MAC randomization in the identified device data.</li>
          <li>The user can restrict or filter the data by setting a tag and a date/time range in the navigation bar.
          </li>
        </ul>
        <small>
          Optional URL Parameters:
          <pre><code>startTimestamp: Start of the selected timerange, UNIX timestamp</code></pre>
          <pre><code>endTimestamp: End of the selected timerange, UNIX timestamp</code></pre>
          <pre><code>tags: the selected tag as a single string</code></pre>
        </small>

        <h3>Tracking View</h3>
        <small>
          <pre><code>/mac</code></pre>
        </small>
        <ul>
          <li>The user can add named aliases for MAC addresses to be tracked.</li>
          <li>The presence patterns of tracked aliases are displayed in a swimlane graph</li>
          <li>The user can zoom into the swimlane graph and move around in the date/time range</li>
          <li>The user can restrict or filter the data by setting a tag and a date/time range in the navigation bar.
          </li>
        </ul>
        <small>
          Optional URL Parameters:
          <pre><code>startTimestamp: Start of the selected timerange, UNIX timestamp</code></pre>
          <pre><code>endTimestamp: End of the selected timerange, UNIX timestamp</code></pre>
          <pre><code>tags: the selected tag as a single string</code></pre>
        </small>


        <h2><a name="rest">REST API</a></h2>

        <h3>Devices</h3>
        <small>
          <p>
            Get devices identified in a certain time range and with a certain tag:
          <pre><code>GET: /api/device/query?starTimestamp={timestamp}&endTimestamp={timestamp}&tags={tag}</code></pre>
          </p>
          <p>
            Get devices seen in the last 5 minutes:
          <pre><code>GET: /api/device/lastFive</code></pre>
          </p>
          <p>
            Get devices seen in the last hour:
          <pre><code>GET: /api/device/lastHour</code></pre>
          </p>
          <p>
            Get devices seen in the last day:
          <pre><code>GET: /api/device/lastDay</code></pre>
          </p>
        </small>

        <h3>Locations</h3>
        <small>
          <p>
            For the location endpoints, the backend expects a URL-encoded query object. The query object should be a
            MongoDB JavaScript
            query object and you should URL-encode it according to the
            <a href="http://www.w3schools.com/tags/ref_urlencode.asp">standards.</a>
          </p>

          <p>
          <pre><code>GET: /api/locations?query={URL-encoded MongoDB query object}</code></pre>
          </p>
          <p>
            On this endpoint, you can choose what parameters you use. You can use arbitrary MongoDB query objects.
          </p>
        </small>


        <h3>Sessions</h3>
        <small>
          <p>
            For some of the session endpoints, the backend expects a URL-encoded query object. The query object should
            be a
            MongoDB JavaScript query object and you should URL-encode it according to the
            <a href="http://www.w3schools.com/tags/ref_urlencode.asp">standards.</a>
          </p>

          <p>
            On this endpoint, you can choose what parameters you use. You can use arbitrary MongoDB query objects and
            can filter sessions
            arbitrarily.
          <pre><code>GET: /api/session?query={URL-encoded MongoDB query object}</code></pre>
          </p>
          <p>
            Get the aggregated session data for the utilization view, according to the passed timestamps and tag:
          <pre><code>GET: /api/session/reduce?startTimestamp={timestamp}&endTimestamp={timestamp}&tags={tag}</code></pre>
          </p>
        </small>

        <h3>Packets</h3>
        <small>
          <p>
            For some of the packet endpoints, the backend expects a URL-encoded query object. The query object should
            be a
            MongoDB JavaScript query object and you should URL-encode it according to the
            <a href="http://www.w3schools.com/tags/ref_urlencode.asp">standards.</a>
          </p>

          <p>
            On this endpoint, you can choose what parameters you use. You can use arbitrary MongoDB query objects and
            can filter packets arbitrarily and also use MongoDB features like sorting.
          <pre><code>GET: /api/packets?query={URL-encoded MongoDB query object}</code></pre>
          </p>
          <p>
            Get the count of total packets fullfilling the query object. This is used in the pagination.
          <pre><code>GET: /api/packets/count?query={URL-encoded MongoDB query object}</code></pre>
          </p>
        </small>


        <h2><a name="workers">Async workers</a></h2>

        <p>
          In order to have aggregated information to answer more sophisticated questions (see <a
          href="/#/usecase#questions">here</a>)
          our system has to be able to compute the necessary aggregations. Since the amount of packet data which must be
          used for the
          aggregations is just too large, the aggregations cannot be done on-demand when the backend receives a
          corresponding query from
          the user. Hence, probr-analysis employs a worker system, that lets asynchronous tasks run in parallel in a
          regular interval, in order
          to aggregate the wanted information a priori.
        </p>

        <p>
          There are three worker tasks in probr-analysis:
        <ul>
          <li>Session-Worker</li>
          <li>Location-Worker</li>
          <li>Device-Worker</li>
        </ul>
        </p>
        <p>
          The worker tasks are encapsulated in a separate node app, which can be started independently from the rest of
          probr-analysis.
          You can find the code for the worker tasks <a
          href="https://github.com/probr/probr-analysis/tree/master/worker">here</a>. In the following, the computations
          that are conducted by the
          workers are explained.
        </p>

        <h3><a name="sessions-worker">Sessions</a></h3>

        <p>
          A session is defined as the time interval that a certain MAC address was present at a location monitored by
          our
          sniffing devices. Our definition of a MAC address being 'present' is: The device with said MAC address is
          present if
          we have collected probes for it with less than 5 minutes in between. Let's look at an example:
        </p>
        <img class="doc-img img-responsive" src="assets/images/sessions.png"/>

        <p>
          Here, the packets #1 and #2 belong to the same session, because they are less than 5 minutes apart. The next
          packet, although
          from the same MAC address, does not belong to the same session since the time between is too large. Hence, it
          starts a new session
          of its own. A session that consists only of one packet (and hence has a duration of 0) is not considered in
          our system. Depending
          on the use case, you might want to tweak the 5 minute session threshold and also decide to ignore sessions
          below a certain length.
        </p>

        <p>
          In the actual implementation, the session aggregation task is implemented as a MapReduce algorithm. You can
          check out the
          corresponding code <a
          href="https://github.com/probr/probr-analysis/blob/master/worker/components/session/session.mapreduce.js">here</a>.
        </p>


        <h3><a name="locations-worker">Locations</a></h3>

        <link rel="stylesheet" href="components/pseudocode/pseudocode.min.css">
        <script src="components/pseudocode/pseudocode.min.js"></script>

        <p>
          How is it possible to compute geographical locations out of the sniffed probe requests/packets ? The fact that
          the probe
          requests contain the measured signal strength makes it possible to compute locations by <a
          href="https://en.wikipedia.org/wiki/Trilateration">trilateration</a>.
        </p>
        <p>
          To employ trilateration, the user has to set a correct latitude and longitude for the sniffing devices when
          initially setting up the probr-core sniffing system. These will in turn assign their lat/lng location data to each
          of the packets they sniff. Now each packet contains a lat/lng location and a measured signal strength in dbM.
        </p>
        <p>
          The first step the location task performs is to extract raw locations from the sniffed packets. This is accomplished
          through a MapReduce algorithm that runs directly on the MongoDB. The MapReduce algorithm first maps together all packets
          that were sniffed within the same minute and have the same source MAC address. Then it extracts location and
          signal strength for all packets in that minute/MAC address mapping. The raw loaction now links this array of
          lat/lng locations and signal strength values to a time and MAC address key. These objects are then stored in a raw locations
          collection.
        </p>
        <p>
          Then the algorithm iterates incrementally over the raw locations and performs the actual trilateration. The algorithm is
          outlined in the following listing:
        </p>
        <img class="doc-img img-responsive" src="assets/images/location_algorithm.png"/>


        <p>
          This process is vizualized in the following animation:
        </p>
        <img class="doc-img img-responsive" src="assets/images/gifs/location.gif"/>

        <h3><a name="devices-worker">Devices</a></h3>

        <p>
          The device task runs on a regular interval and takes into consideration all packets that have been added to the system since
          the last time the task ran. On every run, the device task goes through all packets, and extracts unique MAC addresses.
          If the MAC address is already identified as a device by a previous run of the task, only its last_seen property is updated to the
          timestamp of the packet. If the MAC address is not yet identified, the device task consults the
          <a href="http://standards-oui.ieee.org/oui.txt"> IEEE IOU</a> database for MAC address vendor prefixes. By querying the database
          with the first three octets of the corresponding MAC address, we can gather information about the vendor of that device.
        </p>
      </div>

    </div>

  </div>
</div>

</div>
<footer></footer>
